{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Faster RCNN Flow\n",
    "1. Feature extraction from image\n",
    "2. Creating anchor targets\n",
    "3. Locations and objectness score prediction from the RPN network\n",
    "4. Taking the top N locations and their objectness scores aka proposal layer\n",
    "5. Passing these top N locations through Fast R-CNN network and generating locations and cls predictions for each location is suggested in 4.\n",
    "6. generating proposal targets for each location suggested in 4\n",
    "7. Using 2 and 3 to calculate rpn_cls_loss and rpn_reg_loss.\n",
    "8. using 5 and 6 to calculate roi_cls_loss and roi_reg_loss.\n",
    "\"\"\"\n",
    "\n",
    "# Flow\n",
    "# 1. region Proposal network(RPN) -> 3 * 3 sliding window 당 anchor boxes 9개가 나온다.\n",
    "# 2. RPN loss function\n",
    "# 3. Region of interest Pooling (ROI)\n",
    "# 4. ROI loss functions\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "# 기본 이미지\n",
    "image = torch.zeros((1,3,800,800)).float()\n",
    "\n",
    "# y1, x1, y2, x2 format으로 이루어져 있음 / 현재는 2개의 B.B GT 생성.\n",
    "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]])\n",
    "# 위에서 2개의 B.B의 object를 명시한다.\n",
    "labels = torch.LongTensor([6,8])\n",
    "\n",
    "sub_sample = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_img = torch.zeros((1,3, 800, 800)).float()\n",
    "# print(dummy_img)\n",
    "\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "# Q. torchvision cuda 찾아보기\n",
    "fe = list(model.features)\n",
    "#print(fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 64, 224, 224])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 64, 224, 224])\n",
      "\n",
      "\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 64, 224, 224])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 64, 224, 224])\n",
      "\n",
      "\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 64, 112, 112])\n",
      "\n",
      "\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 128, 112, 112])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 128, 112, 112])\n",
      "\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 128, 112, 112])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 128, 112, 112])\n",
      "\n",
      "\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 128, 56, 56])\n",
      "\n",
      "\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 256, 56, 56])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 256, 56, 56])\n",
      "\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 256, 56, 56])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 256, 56, 56])\n",
      "\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 256, 56, 56])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 256, 56, 56])\n",
      "\n",
      "\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 256, 28, 28])\n",
      "\n",
      "\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 28, 28])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 28, 28])\n",
      "\n",
      "\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 28, 28])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 28, 28])\n",
      "\n",
      "\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 28, 28])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 28, 28])\n",
      "\n",
      "\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 512, 14, 14])\n",
      "\n",
      "\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 14, 14])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 14, 14])\n",
      "\n",
      "\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 14, 14])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 14, 14])\n",
      "\n",
      "\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 14, 14])\n",
      "\n",
      "\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 14, 14])\n",
      "\n",
      "\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 512, 7, 7])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_temp = torch.zeros((1,3, 224, 224)).float()\n",
    "for i in fe:\n",
    "    print(i)\n",
    "    img_temp = i(img_temp)\n",
    "    print(img_temp.size())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# Layer를 저장하는 공간이다. \n",
    "reg_features = []\n",
    "\n",
    "k = dummy_img.clone() # 깊은복사. copyTo: 얕은 복사 --> 즉 원본이 변하면 output도 변한다.\n",
    "for i in fe:\n",
    "    \n",
    "    # K = feature map을 의미한다. \n",
    "    k = i(k)\n",
    "    \n",
    "    # VGG network의 마지막 부분만 제외한다.\n",
    "    # 3 * 3 * 512 까지만 conv을 적용한다.\n",
    "    # conv5_3 층 까지만 적용하는 것이다.\n",
    "    # 즉 마지막 층의 maxpooling 전까지 적용 \n",
    "    if k.size()[2] < 800 // 16:\n",
    "        break\n",
    "        \n",
    "    reg_features.append(i)\n",
    "    out_channels = k.size()[1]\n",
    "\n",
    "print(len(reg_features)) # 31\n",
    "print(out_channels) # 512\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      ")\n",
      "\n",
      "\n",
      "torch.Size([1, 512, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "# convert list into a sequential module\n",
    "faster_rcnn_fe_extractor = nn.Sequential(*reg_features)\n",
    "print(faster_rcnn_fe_extractor)\n",
    "print(\"\\n\")\n",
    "out_map = faster_rcnn_fe_extractor(image)\n",
    "print(out_map.size()) # torch.Size([1, 512, 50, 50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n우리가 anchor를 뽑아 내는 것은 input image에서 뽑아내는 것이다.\\n즉 현재 input 이 800 * 800 이며 \\n마지막 feature map의 크기가 50 * 50 이기 때문에 \\n16 * 16 픽셀이 feature map의 1개의 픽셀과 correspoding 하다는 것이다. \\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anchor boxes\n",
    "\n",
    "# 1. Generate Anchor at a feature map location\n",
    "# 2. Generate Anchor at all the feature map location.\n",
    "# 3. Assign the labels and location of objects (with respect to the anchor) to each and every anchor.\n",
    "# 4. Generate Anchor at a feature map location\n",
    "\n",
    "# 현재는 8, 16, 32 형태로 anchor box를 생성할 것이며\n",
    "# 비율은 0.5, 1, 2 ratio로 진행할 것이다. \n",
    "# sub sampling은 16 ( 800px -> 50px 로 줄였기 때문에 나온 숫자. )\n",
    "# sub sampling이 무엇을 의미하는 것일 까? \n",
    "\n",
    "\"\"\"\n",
    "우리가 anchor를 뽑아 내는 것은 input image에서 뽑아내는 것이다.\n",
    "즉 현재 input 이 800 * 800 이며 \n",
    "마지막 feature map의 크기가 50 * 50 이기 때문에 \n",
    "16 * 16 픽셀이 feature map의 1개의 픽셀과 correspoding 하다는 것이다. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "(9, 4)\n"
     ]
    }
   ],
   "source": [
    "ratio = [0.5, 1, 2]\n",
    "anchor_scales = [8, 16, 32]\n",
    "\n",
    "anchor_base = np.zeros((len(ratio) * len(anchor_scales), 4), dtype=np.float32)\n",
    "\n",
    "print(anchor_base)\n",
    "print(anchor_base.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 90.509668 181.019336\n",
      "0 1 181.019336 362.038672\n",
      "0 2 362.038672 724.077344\n",
      "1 0 128.000000 128.000000\n",
      "1 1 256.000000 256.000000\n",
      "1 2 512.000000 512.000000\n",
      "2 0 181.019336 90.509668\n",
      "2 1 362.038672 181.019336\n",
      "2 2 724.077344 362.038672\n",
      "[[ -37.254833  -82.50967    53.254833   98.50967 ]\n",
      " [ -82.50967  -173.01933    98.50967   189.01933 ]\n",
      " [-173.01933  -354.03867   189.01933   370.03867 ]\n",
      " [ -56.        -56.         72.         72.      ]\n",
      " [-120.       -120.        136.        136.      ]\n",
      " [-248.       -248.        264.        264.      ]\n",
      " [ -82.50967   -37.254833   98.50967    53.254833]\n",
      " [-173.01933   -82.50967   189.01933    98.50967 ]\n",
      " [-354.03867  -173.01933   370.03867   189.01933 ]]\n"
     ]
    }
   ],
   "source": [
    "# 이게 가장 처음의 image 16 * 16 픽셀부분에 대한 anchor box 9개의 좌표를 의미한다.\n",
    "# 다른 말로 feature map 첫번째 픽셀의 input image에서의 anchor location을 의미한다. \n",
    "\n",
    "# 따라서 우리는 17500(50 * 50 * 9) 개의 anchor가 필요하다.\n",
    "\n",
    "# ctr: sliding window 에 대한 가운데 좌표를 의미한다. \n",
    "ctr_y = sub_sample / 2.0\n",
    "ctr_x = sub_sample / 2.0\n",
    "\n",
    "for i in range(len(ratio)):\n",
    "    for j in range(len(anchor_scales)):\n",
    "        h = sub_sample * anchor_scales[j] * np.sqrt(ratio[i])\n",
    "        w = sub_sample * anchor_scales[j] * np.sqrt(1.0 / ratio[i])\n",
    "        print(\"%d %d %f %f\"%(i, j, h, w))\n",
    "        \n",
    "        # 0 ~ 9\n",
    "        index = i * len(anchor_scales) + j\n",
    "        \n",
    "        anchor_base[index,0] = ctr_y - h / 2.0\n",
    "        anchor_base[index,1] = ctr_x - w / 2.0\n",
    "        anchor_base[index,2] = ctr_y + h / 2.0\n",
    "        anchor_base[index,3] = ctr_x + w / 2.0\n",
    "        \n",
    "print(anchor_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16  32  48  64  80  96 112 128 144 160 176 192 208 224 240 256 272 288\n",
      " 304 320 336 352 368 384 400 416 432 448 464 480 496 512 528 544 560 576\n",
      " 592 608 624 640 656 672 688 704 720 736 752 768 784 800]\n"
     ]
    }
   ],
   "source": [
    "fe_size = (800//16)\n",
    "ctr_x = np.arange(16, (fe_size+1) * 16, 16)\n",
    "ctr_y = np.arange(16, (fe_size+1) * 16, 16)\n",
    "print(ctr_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500, 2])\n"
     ]
    }
   ],
   "source": [
    "ctr = torch.zeros((len(ctr_x)*len(ctr_y),2)).float()\n",
    "index = 0\n",
    "for x in range(len(ctr_x)):\n",
    "    for y in range(len(ctr_y)):\n",
    "        ctr[index, 1] = ctr_x[x] - 8.0\n",
    "        ctr[index, 0] = ctr_y[y] - 8.0\n",
    "        index = index + 1\n",
    "print(ctr.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22500, 4])\n"
     ]
    }
   ],
   "source": [
    "anchors = torch.zeros((fe_size * fe_size * 9),4)\n",
    "\n",
    "index = 0\n",
    "for c in ctr:\n",
    "    # C = ctr의 값들을 불러온다. ex) tensor([8. , 8.])\n",
    "    ctr_y , ctr_x = c\n",
    "    for i in range(len(ratio)):\n",
    "        for j in range(len(anchor_scales)):\n",
    "            h = sub_sample * anchor_scales[j] * np.sqrt(ratio[i])\n",
    "            w = sub_sample * anchor_scales[j] * np.sqrt(1./ ratio[i])\n",
    "            \n",
    "            anchors[index, 0] = ctr_y - h / 2.\n",
    "            anchors[index, 1] = ctr_x - w / 2.\n",
    "            anchors[index, 2] = ctr_y + h / 2.\n",
    "            anchors[index, 3] = ctr_x + w / 2.\n",
    "            \n",
    "            index += 1\n",
    "print(anchors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image 의 모든 anchor box에 대해서 객체의 레이블과 위치를 할당해야 한다. \n",
    "# intersection - over - union이 가장 높은 앵커\n",
    "# IoU가 GT와 0.7 겹치는 앵커 박스를 찾는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "# 일단 생성된 anchor box 에서 이미지 안에 있는 것만 선택 \n",
    "# index를 선택한다. \n",
    "index_inside = np.where(\n",
    "        (anchors[:, 0] >= 0) &\n",
    "        (anchors[:, 1] >= 0) &\n",
    "        (anchors[:, 2] <= 800) &\n",
    "        (anchors[:, 3] <= 800)\n",
    "    )[0]\n",
    "print(index_inside.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ... -1 -1 -1]\n",
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "label = np.empty((len(index_inside), ), dtype=np.int32)\n",
    "label.fill(-1)\n",
    "print(label)\n",
    "print(label.shape)\n",
    "#Out = (8940, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 13.4903,  10.7452, 194.5097, 101.2548],\n",
      "        [ 29.4903,  10.7452, 210.5097, 101.2548],\n",
      "        [ 45.4903,  10.7452, 226.5097, 101.2548],\n",
      "        ...,\n",
      "        [573.4904, 698.7452, 754.5096, 789.2548],\n",
      "        [589.4904, 698.7452, 770.5096, 789.2548],\n",
      "        [605.4904, 698.7452, 786.5096, 789.2548]])\n"
     ]
    }
   ],
   "source": [
    "valid_anchor = anchors[index_inside]\n",
    "print(valid_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 anchor 중에서 IoU를 계산해서 object가 있는지 없는지를 판단해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940, 2)\n",
      "[[0.06811669 0.        ]\n",
      " [0.07083762 0.        ]\n",
      " [0.07083762 0.        ]\n",
      " ...\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# IoU 계산 \n",
    "ious = np.zeros((len(valid_anchor),2), dtype = np.float32)\n",
    "\n",
    "# for문 2개 돌리면 속도가 너무 느릴것 같다. 이부분 어떻게 하면 속도를 올릴까?\n",
    "# numpy 배열 어떻게 적용할지 생각해 보기 \n",
    "for index_anchor, i in enumerate(valid_anchor):\n",
    "    y1, x1, y2, x2 = i\n",
    "    anchor_area = (y2 - y1) * (x2 - x1)\n",
    "    for index_bb, j in enumerate(bbox):\n",
    "        b_y1, b_x1, b_y2, b_x2 = j\n",
    "        box_area = (b_y2 - b_y1) * (b_x2 - b_x1)\n",
    "        \n",
    "        # 우리가 알고 싶은 것은 예측한 anchor 박스와 GT가 얼마나 겹치는지 판단.\n",
    "        # 왼쪽 상단 좌표값은 큰 값으로\n",
    "        # 오른쪽 하단 좌표값은 작은 값으로 선택 \n",
    "        inter_x1 = max([b_x1, x1])\n",
    "        inter_y1 = max([b_y1, y1])\n",
    "        inter_x2 = min([b_x2, x2])\n",
    "        inter_y2 = min([b_y2, y2])\n",
    "        \n",
    "        if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "            iter_area = (inter_y2 - inter_y1) * (inter_x2 - inter_x1)\n",
    "            iou = iter_area / (anchor_area+ box_area - iter_area)            \n",
    "        else:\n",
    "            iou = 0.\n",
    "            \n",
    "        ious[index_anchor, index_bb] = iou\n",
    "# shape 8940 * 2\n",
    "# 이게 의미하는 바는 현재 image 에서는 800 * 800 안에 있는 anchor 수가 8940 이며\n",
    "# 지금 image 안에는 2개의 object가 존재하고 \n",
    "# 각각의 object 당 object가 들어있을 경우의 확률 및 object가 하나도 없는 때는 0을 포함하고 있음 \n",
    "print(ious.shape)\n",
    "print(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2262 5620]\n",
      "0.68130493\n",
      "0.61035156\n",
      "[0.68130493 0.61035156]\n"
     ]
    }
   ],
   "source": [
    "# X축끼리 비교 Y축 끼리 비교 \n",
    "gt_argmax_ious = ious.argmax(axis=0)\n",
    "print(gt_argmax_ious)\n",
    "\n",
    "print(ious[2262,0])\n",
    "print(ious[5620,1])\n",
    "gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]\n",
    "print(gt_max_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.06811669 0.07083762 0.07083762 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# 2개의 object 대소 비교하는 것이다. \n",
    "# 가자큰 object 번호를 선택하게 되어 있다. \n",
    "# 따라서 크기는 8940 이며 여기서의 0과 1은 오브젝트를 의미한다. \n",
    "argmax_ious = ious.argmax(axis=1)\n",
    "print(argmax_ious.shape)\n",
    "print(argmax_ious)\n",
    "\n",
    "# 해당 object의 확률 값을 의미한다. \n",
    "max_ious = ious[np.arange(len(index_inside)), argmax_ious]\n",
    "print(max_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2262 2508 5620 5628 5636 5644 5866 5874 5882 5890 6112 6120 6128 6136\n",
      " 6358 6366 6374 6382]\n"
     ]
    }
   ],
   "source": [
    "gt_argmax_ious = np.where(ious == gt_max_ious)[0]\n",
    "print(gt_argmax_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]]\n",
      "[3 3]\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(8).reshape(4,2) \n",
    "print(a)\n",
    "print(a.argmax(axis = 0))\n",
    "print(a.argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. argmax_ious — Tells which ground truth object has max iou with each anchor.\n",
    "--> GT의 object 값을 의미한다. \n",
    "\n",
    "2. max_ious — Tells the max_iou with ground truth object with each anchor.\n",
    "--> object의 IoU값을 의미한다. \n",
    "\n",
    "3. gt_argmax_ious — Tells the anchors with the highest Intersection-over-Union (IoU) overlap with a ground-truth box.\n",
    "--> GT와 가장 크게 겹치는 anchor 박스를 의미한다. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 부분 paper 에서는 0.7로 설정되어 있다. \n",
    "pos_iou_threshold = 0.6\n",
    "neg_iou_threshold = 0.3\n",
    "\n",
    "# label 은 8940 의 shape을 가지고 있다. \n",
    "# 해당 shape 은 image 안에 있는 anchor의 개수를 의미한다.\n",
    "# 여기서 label을 하는 것은 anchor가 positive 인지 negative 인지를 알 수있다.\n",
    "# 현재는 -1로 초기화 되어있다. \n",
    "\n",
    "# max_ious는 object와 B.B gt가 얼마나 겹치는지 %를 의미한다. 30% 아래이면 0 \n",
    "label[max_ious< neg_iou_threshold] = 0\n",
    "label[gt_argmax_ious] = 1 # IoU가 가장 큰 값도 1\n",
    "label[max_ious >= pos_iou_threshold] = 1 # 0.7 이상이여야지만 1이다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2262 2269 2276 2508 2515 2522 2754 2761 2768 3000 3007 3959 3966 4233\n",
      " 4240 5620 5628 5636 5644 5866 5874 5882 5890 6112 6120 6128 6136 6358\n",
      " 6366 6374 6382]\n"
     ]
    }
   ],
   "source": [
    "print(np.where(label == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.0\n"
     ]
    }
   ],
   "source": [
    "pos_ratio = 0.5 \n",
    "n_sample = 256\n",
    "\n",
    "n_pos = pos_ratio * n_sample\n",
    "print(n_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# positie samples\n",
    "pos_index = np.where(label == 1)[0]\n",
    "print(len(pos_index))\n",
    "\n",
    "# 만약 posive 가 많을 경우 해당 부분의 개수를 줄여주는 코드\n",
    "if len(pos_index) > n_pos:\n",
    "    disable_index = np.random.choice(pos_index, size = (len(pos_index) - n_pos), replace=False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7936\n",
      "7690\n"
     ]
    }
   ],
   "source": [
    "# negative samples code \n",
    "# 만약 negative가 많을 경우 빼주는 코드이다. \n",
    "\n",
    "n_neg = n_sample * np.sum(label == 1)\n",
    "print(n_neg)\n",
    "neg_index = np.where(label == 0)[0]\n",
    "print(len(neg_index))\n",
    "\n",
    "if len(neg_index) > n_neg:\n",
    "    disable_index = np.random.choice(neg_index, size=(len(neg_index) - n_neg), replace = False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1891 1897 1903 ... 8561 8565 8569]\n",
      "torch.Size([8940, 4])\n",
      "tensor([ 20.,  30., 400., 500.])\n",
      "tensor([300., 400., 500., 600.])\n"
     ]
    }
   ],
   "source": [
    "# 모든 anchor에 대한 GT 생성\n",
    "print(np.where(argmax_ious == 1)[0])\n",
    "max_iou_bbox = bbox[argmax_ious]\n",
    "print(max_iou_bbox.shape)\n",
    "print(max_iou_bbox[0,:])\n",
    "print(max_iou_bbox[1891,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size 안에 있는 anchor의 \n",
    "# center 와 height 와 width 를 기록한다.\n",
    "height = valid_anchor[:, 2] - valid_anchor[:, 0]\n",
    "width = valid_anchor[:, 3] - valid_anchor[:, 1]\n",
    "ctr_y = valid_anchor[:, 0] + 0.5 * height\n",
    "ctr_x = valid_anchor[:, 1] + 0.5 * width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT의 center 와 height 와 width를 의미한다. \n",
    "base_height = max_iou_bbox[:, 2] - max_iou_bbox[:, 0]\n",
    "base_width = max_iou_bbox[:, 3] - max_iou_bbox[:, 1]\n",
    "base_ctr_y = max_iou_bbox[:, 0] + 0.5 * base_height\n",
    "base_ctr_x = max_iou_bbox[:, 1] + 0.5 * base_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google_images_download'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-529bfb3bea57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle_images_download\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgoogle_images_download\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google_images_download'"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download\n",
    "from PIL import Image\n",
    "import ssl\n",
    "import os\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "def imageCrawling(keyword, dir):\n",
    "    response = google_images_download.googleimagesdownload()\n",
    "\n",
    "    arguments = {\"keywords\": keyword,\n",
    "                 \"limit\": 1500,\n",
    "                 \"print_urls\": True,\n",
    "                 \"no_directory\": True,\n",
    "                 'output_directory': dir,\n",
    "                 \"chromedriver\": \"C:/Users/user/Downloads/chromedriver_win32\"\n",
    "                 }\n",
    "    paths = response.download(arguments)\n",
    "    print(paths)\n",
    "\n",
    "\n",
    "def img_delete():\n",
    "    img_dir = r\"C:/Users/user/Pictures/Saved Pictures\"\n",
    "    for filename in os.listdir(img_dir):\n",
    "        try:\n",
    "            with Image.open(img_dir + '/' + filename) as im:\n",
    "                print(\"ok\")\n",
    "        except:\n",
    "            print(img_dir + \"/\" + filename)\n",
    "            os.remove(img_dir + \"/\" + filename)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    imageCrawling('do not wash symbol', \"C:/Users/user/Pictures/Saved Pictures/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
